# PowerShell RAG Pipeline å¸¸ç”¨æŒ‡ä»¤æ‰‹å†Š

## ğŸ“ ç›®éŒ„ç®¡ç†èˆ‡æŸ¥è©¢æŒ‡ä»¤

### åŸºæœ¬ç›®éŒ„æŸ¥è©¢
```powershell
# æŸ¥çœ‹ç•¶å‰ç›®éŒ„å…§å®¹
Get-ChildItem
dir
ls

# æŸ¥çœ‹ç‰¹å®šè³‡æ–™å¤¾å…§å®¹
Get-ChildItem data/
dir data\

# æŸ¥çœ‹æª”æ¡ˆè©³ç´°è³‡è¨Šï¼ˆåŒ…å«å¤§å°ã€ä¿®æ”¹æ™‚é–“ï¼‰
Get-ChildItem -Force | Format-Table Name, Length, LastWriteTime

# éæ­¸æŸ¥çœ‹æ‰€æœ‰å­ç›®éŒ„æª”æ¡ˆ
Get-ChildItem -Recurse

# æŸ¥çœ‹ç‰¹å®šå‰¯æª”åçš„æª”æ¡ˆ
Get-ChildItem *.jsonl
Get-ChildItem *.pdf

# æŸ¥çœ‹æª”æ¡ˆå…§å®¹å‰å¹¾è¡Œ
Get-Content data\questions.jsonl | Select-Object -First 5
Get-Content packages\rag\generation\Answer_llm\tests\results\test_answers.jsonl | Select-Object -First 3

# çµ±è¨ˆæª”æ¡ˆè¡Œæ•¸
Get-Content data\questions.jsonl | Measure-Object -Line
```

### é€²éšæŸ¥è©¢èˆ‡ç¯©é¸
```powershell
# æŸ¥æ‰¾åŒ…å«ç‰¹å®šæ–‡å­—çš„æª”æ¡ˆ
Get-ChildItem -Recurse | Select-String "llama3.1"

# æŸ¥çœ‹æª”æ¡ˆå¤§å°ä¸¦æ’åº
Get-ChildItem | Sort-Object Length -Descending | Format-Table Name, @{Name="Size(KB)";Expression={[math]::Round($_.Length/1KB,2)}}

# æŸ¥çœ‹æœ€è¿‘ä¿®æ”¹çš„æª”æ¡ˆ
Get-ChildItem | Sort-Object LastWriteTime -Descending | Select-Object -First 10

# æŸ¥çœ‹ç‰¹å®šæ™‚é–“ç¯„åœçš„æª”æ¡ˆ
Get-ChildItem | Where-Object {$_.LastWriteTime -gt (Get-Date).AddDays(-1)}
```

## ğŸ—‚ï¸ æª”æ¡ˆèˆ‡è³‡æ–™å¤¾æ“ä½œ

### å»ºç«‹æ¨™æº–ç›®éŒ„çµæ§‹
```powershell
# å»ºç«‹æ¨è–¦çš„è³‡æ–™å¤¾çµæ§‹
New-Item -ItemType Directory -Force data/input
New-Item -ItemType Directory -Force data/samples  
New-Item -ItemType Directory -Force outputs
New-Item -ItemType Directory -Force tests/data
New-Item -ItemType Directory -Force tests/results
New-Item -ItemType Directory -Force tests/benchmarks

# å»ºç«‹ .gitkeep æª”æ¡ˆä¿æŒè³‡æ–™å¤¾çµæ§‹
New-Item -ItemType File -Force data/input/.gitkeep
New-Item -ItemType File -Force outputs/.gitkeep
New-Item -ItemType File -Force tests/results/.gitkeep
```

### æª”æ¡ˆç§»å‹•èˆ‡æ•´ç†
```powershell
# ç§»å‹• PDF åˆ° input è³‡æ–™å¤¾
Move-Item data/*.pdf data/input/

# ç§»å‹•æ¸¬è©¦æª”æ¡ˆåˆ°å°æ‡‰è³‡æ–™å¤¾
Move-Item data/sample_questions_20.jsonl data/samples/
Move-Item data/bench tests/benchmarks/
Move-Item data/chunk_k*.jsonl tests/results/
Move-Item data/keywords.jsonl tests/results/

# è¤‡è£½æª”æ¡ˆï¼ˆä¿ç•™åŸæª”ï¼‰
Copy-Item source_file.jsonl destination/

# é‡æ–°å‘½åæª”æ¡ˆ
Rename-Item old_name.jsonl new_name.jsonl
```

## ğŸ”§ ç’°å¢ƒè®Šæ•¸è¨­å®š

### Ollama + OpenAI ç›¸å®¹æ¨¡å¼
```powershell
# åŸºæœ¬è¨­å®š
$env:LLM_MODE="OPENAI_COMPAT"
$env:OPENAI_BASE_URL="http://localhost:11434/v1"
$env:OPENAI_API_KEY="ollama"

# æ¨¡å‹è¨­å®š
$env:MODEL_QUESTION="llama3.1:latest"
$env:MODEL_KEYWORDS="llama3.1:latest" 
$env:MODEL_ANSWER="llama3.1:8b"

# æŸ¥çœ‹ç•¶å‰ç’°å¢ƒè®Šæ•¸
Get-ChildItem Env: | Where-Object {$_.Name -like "*LLM*" -or $_.Name -like "*MODEL*" -or $_.Name -like "*OPENAI*"}

# æ¸…é™¤ç’°å¢ƒè®Šæ•¸
Remove-Item Env:MODEL_ANSWER -ErrorAction SilentlyContinue
```

### MOCK æ¸¬è©¦æ¨¡å¼
```powershell
$env:LLM_MODE="MOCK"
# MOCK æ¨¡å¼ä¸éœ€è¦å…¶ä»–è¨­å®š
```

## ğŸš€ RAG Pipeline åŸ·è¡ŒæŒ‡ä»¤

### 1. Chunk åˆ‡åˆ†èˆ‡ç´¢å¼•
```powershell
# åŸºæœ¬ chunk åˆ‡åˆ†
python scripts/build_chunks_jsonl.py

# åŒ…å« OCR åŠŸèƒ½
python scripts/build_chunks_jsonl.py --ocr

# å®Œæ•´åŠŸèƒ½ï¼ˆJSONL + TXT + OCR + FAISSï¼‰
python scripts/build_chunks_jsonl.py --preset full

# è‡ªè¨‚è¨­å®š
python scripts/build_chunks_jsonl.py --input data/input --out indices/chunks.jsonl --chunk-size 1200 --overlap 150
```

### 2. å•é¡Œç”Ÿæˆ
```powershell
# ç”Ÿæˆå•é¡Œï¼ˆæ¸¬è©¦ï¼‰
python -m packages.rag.generation.Question_llm.make_questions `
  --index indices `
  --out tests/results/questions.jsonl `
  --langs zh,en `
  --max-chunks 50

# ç”Ÿæˆå•é¡Œï¼ˆæ­£å¼ï¼‰
python -m packages.rag.generation.Question_llm.make_questions `
  --index indices `
  --out outputs/questions.jsonl `
  --langs zh,en `
  --max-chunks 1000
```

### 3. å•é¡Œæª¢æŸ¥èˆ‡æŠ½æ¨£
```powershell
# æª¢æŸ¥å•é¡Œæ ¼å¼
python scripts/check_questions.py outputs/questions.jsonl

# éš¨æ©ŸæŠ½æ¨£æª¢æŸ¥
python scripts/sample_questions.py

# æŸ¥çœ‹å•é¡Œçµ±è¨ˆ
Get-Content outputs/questions.jsonl | Measure-Object -Line
```

### 4. ç­”æ¡ˆç”Ÿæˆ
```powershell
# æ¸¬è©¦æ¨¡å¼ï¼ˆå°‘é‡è³‡æ–™ï¼‰
python -m packages.rag.generation.Answer_llm.core `
  --questions tests/results/questions.jsonl `
  --index indices `
  --out tests/results/test_answers.jsonl `
  --max 10

# æ­£å¼æ¨¡å¼ï¼ˆå¤§é‡è³‡æ–™ï¼‰
python -m packages.rag.generation.Answer_llm.core `
  --questions outputs/questions.jsonl `
  --index indices `
  --out outputs/answers.jsonl `
  --max 1000
```

### 5. ç­”æ¡ˆå¯©æ ¸
```powershell
python -m packages.rag.generation.Critique_llm.run `
  --answers outputs/answers.jsonl `
  --out outputs/answers_pass.jsonl
```

### 6. æœ€çµ‚è³‡æ–™è¼¸å‡º
```powershell
python scripts/export_rag_corpus.py outputs/answers_pass.jsonl
```

## ğŸ“Š æ•ˆèƒ½æ¸¬è©¦èˆ‡ç›£æ§

### é—œéµå­—ç”Ÿæˆæ•ˆèƒ½æ¸¬è©¦
```powershell
# å¿«é€Ÿæ¸¬è©¦ï¼ˆ200 chunksï¼‰
python scripts/bench_keywords.py --max-chunks 200

# è‡ªè¨‚æ¸¬è©¦åƒæ•¸
python scripts/bench_keywords.py --workers 1,4,8,16 --max-chunks 400 --langs zh,en

# æŸ¥çœ‹æ¸¬è©¦çµæœ
Get-Content tests/benchmarks/bench/bench_keywords.csv
```

### ç³»çµ±ç›£æ§
```powershell
# æŸ¥çœ‹ GPU ç‹€æ…‹ï¼ˆéœ€è¦ NVIDIA GPUï¼‰
nvidia-smi

# æŸ¥çœ‹ç³»çµ±è³‡æºä½¿ç”¨
Get-Process | Sort-Object CPU -Descending | Select-Object -First 10

# æŸ¥çœ‹ç£ç¢Ÿç©ºé–“
Get-PSDrive
```

## ğŸ” API æ¸¬è©¦æŒ‡ä»¤

### Ollama API æ¸¬è©¦
```powershell
# æª¢æŸ¥ Ollama æœå‹™ç‹€æ…‹
ollama list
ollama --version

# æ¸¬è©¦æ¨¡å‹æ˜¯å¦å­˜åœ¨
ollama show llama3.1:8b

# æ¸¬è©¦ API ç«¯é»ï¼ˆä½¿ç”¨ Invoke-WebRequestï¼‰
$headers = @{"Content-Type"="application/json"}
$body = @{
    model = "llama3.1:latest"
    messages = @(@{role="user"; content="Hello"})
    max_tokens = 50
} | ConvertTo-Json -Depth 3

Invoke-WebRequest -Uri "http://localhost:11434/v1/chat/completions" -Method POST -Headers $headers -Body $body

# ç°¡å–®æ¸¬è©¦ API å¯ç”¨æ€§
curl http://localhost:11434/v1/models
curl http://localhost:11434/api/tags
```

## ğŸ“ è³‡æ–™æª¢æŸ¥èˆ‡é©—è­‰

### JSONL æª”æ¡ˆæª¢æŸ¥
```powershell
# æª¢æŸ¥ JSONL æ ¼å¼æ˜¯å¦æ­£ç¢º
Get-Content outputs/questions.jsonl | ForEach-Object {
    try {
        $_ | ConvertFrom-Json | Out-Null
        "âœ“"
    } catch {
        "âœ— éŒ¯èª¤è¡Œ: $_"
    }
} | Group-Object | Select-Object Name, Count

# æŸ¥çœ‹ JSON çµæ§‹
Get-Content outputs/questions.jsonl | Select-Object -First 1 | ConvertFrom-Json | ConvertTo-Json -Depth 10

# çµ±è¨ˆé—œéµè³‡è¨Š
$questions = Get-Content outputs/questions.jsonl | ConvertFrom-Json
$questions | Group-Object source | Select-Object Name, Count
$questions | ForEach-Object { $_.questions.Count } | Measure-Object -Sum -Average
```

### æª”æ¡ˆå®Œæ•´æ€§æª¢æŸ¥
```powershell
# æª¢æŸ¥å¿…è¦æª”æ¡ˆæ˜¯å¦å­˜åœ¨
$required_files = @(
    "indices/chunks.txt",
    "outputs/questions.jsonl",
    "outputs/answers.jsonl"
)

foreach ($file in $required_files) {
    if (Test-Path $file) {
        "âœ“ $file å­˜åœ¨"
    } else {
        "âœ— $file ç¼ºå¤±"
    }
}

# æª¢æŸ¥æª”æ¡ˆå¤§å°åˆç†æ€§
Get-ChildItem outputs/ | Where-Object {$_.Length -eq 0} | Select-Object Name
```

## ğŸ§¹ æ¸…ç†èˆ‡ç¶­è­·

### æ¸…ç†æš«å­˜æª”æ¡ˆ
```powershell
# æ¸…ç†æ¸¬è©¦çµæœ
Remove-Item tests/results/*.jsonl -Force

# æ¸…ç† benchmark è³‡æ–™
Remove-Item tests/benchmarks/bench/* -Force

# æ¸…ç† Python å¿«å–
Get-ChildItem -Recurse __pycache__ | Remove-Item -Recurse -Force
Get-ChildItem -Recurse *.pyc | Remove-Item -Force
```

### å‚™ä»½é‡è¦è³‡æ–™
```powershell
# å»ºç«‹å‚™ä»½è³‡æ–™å¤¾
$backup_date = Get-Date -Format "yyyyMMdd_HHmmss"
New-Item -ItemType Directory -Force backups/$backup_date

# å‚™ä»½é‡è¦æª”æ¡ˆ
Copy-Item outputs/ backups/$backup_date/ -Recurse
Copy-Item indices/chunks.txt backups/$backup_date/
Copy-Item data/input/ backups/$backup_date/ -Recurse
```

## ğŸš¨ æ•…éšœæ’é™¤æŒ‡ä»¤

### å¸¸è¦‹å•é¡Œæª¢æŸ¥
```powershell
# æª¢æŸ¥ Python ç’°å¢ƒ
python --version
pip list | findstr "openai\|httpx\|requests"

# æª¢æŸ¥ç¶²è·¯é€£æ¥
Test-NetConnection localhost -Port 11434

# æª¢æŸ¥ç¨‹åºæ˜¯å¦åŸ·è¡Œ
Get-Process | Where-Object {$_.ProcessName -like "*ollama*"}

# æª¢æŸ¥ç’°å¢ƒè®Šæ•¸è¨­å®š
$env:LLM_MODE
$env:MODEL_ANSWER
$env:OPENAI_BASE_URL

# é‡æ–°å•Ÿå‹• Ollama æœå‹™
taskkill /f /im ollama.exe
ollama serve
```

### æ—¥èªŒæŸ¥çœ‹
```powershell
# æŸ¥çœ‹æœ€è¿‘çš„éŒ¯èª¤æ—¥èªŒ
Get-EventLog -LogName Application -Source "Python*" -Newest 10

# æŸ¥çœ‹ç‰¹å®šç¨‹åºæ—¥èªŒ
python -m packages.rag.generation.Answer_llm.core --help
```

## ğŸ’¡ å¯¦ç”¨æŠ€å·§

### æ‰¹æ¬¡æ“ä½œ
```powershell
# æ‰¹æ¬¡æª¢æŸ¥å¤šå€‹ JSONL æª”æ¡ˆ
Get-ChildItem *.jsonl | ForEach-Object {
    Write-Host "æª¢æŸ¥: $($_.Name)"
    Get-Content $_.FullName | Measure-Object -Line | Select-Object -ExpandProperty Lines
}

# æ‰¹æ¬¡è½‰æ›ç·¨ç¢¼
Get-ChildItem *.jsonl | ForEach-Object {
    $content = Get-Content $_.FullName -Encoding UTF8
    $content | Out-File $_.FullName -Encoding UTF8
}
```

### å¿«é€Ÿçµ±è¨ˆ
```powershell
# çµ±è¨ˆ pipeline è™•ç†é€²åº¦
Write-Host "Chunks: $(if (Test-Path indices/chunks.txt) {(Get-Content indices/chunks.txt | Measure-Object -Line).Lines} else {'æœªç”Ÿæˆ'})"
Write-Host "Questions: $(if (Test-Path outputs/questions.jsonl) {(Get-Content outputs/questions.jsonl | Measure-Object -Line).Lines} else {'æœªç”Ÿæˆ'})"
Write-Host "Answers: $(if (Test-Path outputs/answers.jsonl) {(Get-Content outputs/answers.jsonl | Measure-Object -Line).Lines} else {'æœªç”Ÿæˆ'})"
```

---

## ğŸ“ å¿«é€Ÿåƒè€ƒ

**æ¨¡å‹æª¢æŸ¥**: `ollama list`  
**API æ¸¬è©¦**: `curl http://localhost:11434/v1/models`  
**æª”æ¡ˆçµ±è¨ˆ**: `Get-Content file.jsonl | Measure-Object -Line`  
**ç’°å¢ƒè®Šæ•¸**: `Get-ChildItem Env: | Where-Object {$_.Name -like "*MODEL*"}`  
**æ¸…ç†å¿«å–**: `Get-ChildItem -Recurse __pycache__ | Remove-Item -Recurse -Force`

---

*æ­¤æ‰‹å†Šæ¶µè“‹äº† RAG Pipeline é–‹ç™¼èˆ‡ç¶­è­·çš„å¸¸ç”¨ PowerShell æŒ‡ä»¤ï¼Œå»ºè­°æ”¶è—å‚™ç”¨ã€‚*